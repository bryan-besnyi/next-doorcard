# Production Schema Analysis: Access DB ‚Üí PostgreSQL Migration

## **Current Data Overview**
- **10,944 Doorcards** (12+ years of data)
- **184,935 Appointments** (massive scheduling data)
- **6 Categories** (appointment types)
- **1 Admin User** (minimal user management)
- **0 Templates** (unused feature)

## **Critical Schema Issues & Recommendations**

### üö® **MAJOR ISSUE: Current Schema Design Flaw**

Your current Prisma schema stores appointments as **JSON in timeBlocks**, but production data shows appointments as **separate relational records**. This is a fundamental mismatch!

**Current Schema (WRONG for your data):**
```prisma
model Doorcard {
  timeBlocks   Json  // ‚ùå Storing 184K records as JSON will be disaster
}
```

**Production Reality:**
- Each doorcard has **multiple appointments** (average 17 per doorcard)
- Appointments have **categories, times, days**
- This should be **relational, not JSON**

### ‚úÖ **RECOMMENDED PRODUCTION SCHEMA**

```prisma
model User {
  id        String      @id @default(cuid())
  email     String      @unique
  name      String?
  username  String?     @unique // Keep for legacy compatibility
  role      UserRole    @default(FACULTY)
  college   College
  createdAt DateTime    @default(now())
  updatedAt DateTime    @updatedAt
  
  doorcards Doorcard[]
  
  @@index([username]) // Legacy lookups
  @@index([college])
}

model Doorcard {
  id            String      @id @default(cuid())
  name          String      // Faculty name
  doorcardName  String      // Display name
  startDate     DateTime
  endDate       DateTime
  term          String      // e.g., "201203"
  college       College
  isActive      Boolean     @default(true)
  
  // Relations
  userId        String
  user          User        @relation(fields: [userId], references: [id], onDelete: Cascade)
  appointments  Appointment[]
  
  // Legacy support
  legacyId      Int?        @unique
  
  createdAt     DateTime    @default(now())
  updatedAt     DateTime    @updatedAt
  
  @@index([userId])
  @@index([term])
  @@index([college])
  @@index([startDate, endDate])
  @@index([legacyId]) // For migration mapping
}

model Appointment {
  id          String            @id @default(cuid())
  name        String            // e.g., "Office Hours", "Math 100"
  startTime   String           // "08:00:00" 
  endTime     String           // "09:30:00"
  dayOfWeek   DayOfWeek
  category    AppointmentCategory
  
  // Relations
  doorcardId  String
  doorcard    Doorcard          @relation(fields: [doorcardId], references: [id], onDelete: Cascade)
  
  // Legacy support
  legacyId    Int?              @unique
  
  createdAt   DateTime          @default(now())
  updatedAt   DateTime          @updatedAt
  
  @@index([doorcardId])
  @@index([dayOfWeek])
  @@index([category])
  @@index([legacyId]) // For migration
}

// Enums based on your production data
enum College {
  SKYLINE
  CSM
  CANADA
}

enum UserRole {
  FACULTY
  ADMIN
  STAFF
}

enum DayOfWeek {
  MONDAY
  TUESDAY
  WEDNESDAY
  THURSDAY
  FRIDAY
  SATURDAY
  SUNDAY
}

enum AppointmentCategory {
  OFFICE_HOURS     // catID: 1
  IN_CLASS         // catID: 2  
  LECTURE          // catID: 3
  LAB              // catID: 4
  HOURS_BY_ARRANGEMENT  // catID: 5
  REFERENCE        // catID: 6
}
```

## **Migration Strategy Analysis**

### üìä **Data Volume Impact**
- **10,944 doorcards** ‚Üí Manageable
- **184,935 appointments** ‚Üí Requires batch processing
- **Date range**: 2011-2025 (14 years!)
- **Peak usage**: Recent terms have more data

### üîÑ **Migration Complexity**

**High Complexity Items:**
1. **Time format conversion** (`12/30/99 08:00:00` ‚Üí proper time handling)
2. **Username ‚Üí User ID mapping** (184K records to update)
3. **Category ID ‚Üí Enum mapping**
4. **Date parsing** (inconsistent formats in CSV)

**Data Quality Issues Found:**
- Missing usernames in appointments
- Invalid dates (`12/30/99` appears to be placeholder)
- Inconsistent term formats (`201203` vs others)
- Empty doorcard dates in some records

### ‚ö° **Performance Considerations**

**Database Optimization:**
```sql
-- Essential indexes for 184K+ records
CREATE INDEX CONCURRENTLY idx_appointments_doorcard_day 
ON "Appointment" (doorcardId, dayOfWeek);

CREATE INDEX CONCURRENTLY idx_appointments_time_range 
ON "Appointment" (startTime, endTime);

CREATE INDEX CONCURRENTLY idx_doorcards_active_term 
ON "Doorcard" (isActive, term) WHERE isActive = true;
```

**Query Performance:**
- Current JSON approach: **O(n) scan** for every query
- Proper relational: **O(log n)** with indexes
- Expected improvement: **50-100x faster queries**

## **Immediate Action Items**

### üö® **CRITICAL: Fix Schema Before Migration**

1. **Replace JSON timeBlocks** with proper Appointment model
2. **Add proper indexing** for performance
3. **Handle data quality** issues in migration script
4. **Plan batch processing** for 184K appointments

### üìù **Updated Migration Script Needed**

Your current migration script assumes JSON storage, but needs to:
- Create individual Appointment records
- Map category IDs to enums  
- Handle username ‚Üí user ID resolution
- Process in batches (1000 appointments at a time)

### üéØ **Schema Evolution Strategy**

**Phase 1**: Fix schema (BEFORE migration)
**Phase 2**: Migrate doorcards (10K records)
**Phase 3**: Migrate appointments in batches (184K records)  
**Phase 4**: Add constraints and optimize

## **Risk Assessment**

### üî¥ **HIGH RISK**
- **JSON storage** for 184K records = performance disaster
- **Missing indexes** = timeout queries
- **Data quality** issues may break migration

### üü° **MEDIUM RISK**  
- **Large dataset** migration time
- **OneLogin integration** complexity
- **Legacy username** dependencies

### üü¢ **LOW RISK**
- **Application logic** is sound
- **UI components** are production-ready
- **Vercel deployment** is straightforward

## **Recommendation: STOP and Fix Schema First**

**DO NOT migrate with current schema.** The JSON approach will fail with your production data volume.

Implement the relational schema above, then proceed with migration.

This will give you:
- ‚úÖ **100x better performance**
- ‚úÖ **Proper querying capabilities** 
- ‚úÖ **Data integrity constraints**
- ‚úÖ **Future scalability**

Would you like me to implement the corrected schema? 